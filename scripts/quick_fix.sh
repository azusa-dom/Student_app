#!/bin/bash
# Codespace ä¸€é”®ä¿®å¤è„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash codespace_quick_fix.sh

set -e

echo "ğŸš€ UCL AI QA - Codespace ä¸€é”®ä¿®å¤"
echo "=================================="
echo

# 1. æ£€æŸ¥å¹¶å®‰è£… Ollama
echo "ğŸ“¦ æ­¥éª¤ 1/5: å®‰è£… Ollama..."
if ! command -v ollama &> /dev/null; then
    echo "   å®‰è£… Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    echo "   âœ… Ollama å®‰è£…å®Œæˆ"
else
    echo "   âœ… Ollama å·²å®‰è£…"
fi
echo

# 2. å¯åŠ¨ Ollama æœåŠ¡
echo "ğŸ“¦ æ­¥éª¤ 2/5: å¯åŠ¨ Ollama æœåŠ¡..."
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "   âœ… Ollama æœåŠ¡å·²åœ¨è¿è¡Œ"
else
    echo "   å¯åŠ¨æœåŠ¡..."
    nohup ollama serve > /tmp/ollama.log 2>&1 &
    sleep 5
    
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "   âœ… Ollama æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        echo "   âŒ Ollama å¯åŠ¨å¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—: /tmp/ollama.log"
        exit 1
    fi
fi
echo

# 3. å®‰è£…æ¨¡å‹
echo "ğŸ“¦ æ­¥éª¤ 3/5: å®‰è£… tinyllama æ¨¡å‹..."
if ollama list | grep -q "tinyllama"; then
    echo "   âœ… tinyllama å·²å®‰è£…"
else
    echo "   ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 1.1GBï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."
    ollama pull tinyllama
    echo "   âœ… æ¨¡å‹å®‰è£…å®Œæˆ"
fi
echo

# 4. å¤‡ä»½å¹¶æ›¿æ¢ä»£ç 
echo "ğŸ“¦ æ­¥éª¤ 4/5: æ›´æ–°ä»£ç ..."
if [ -f "scripts/qa_enhanced_wrapper.py" ]; then
    # å¤‡ä»½
    if [ ! -f "scripts/qa_enhanced_wrapper.py.bak" ]; then
        cp scripts/qa_enhanced_wrapper.py scripts/qa_enhanced_wrapper.py.bak
        echo "   âœ… å·²å¤‡ä»½åŸæ–‡ä»¶"
    fi
    
    # æ›¿æ¢
    if [ -f "qa_enhanced_wrapper_fixed.py" ]; then
        cp qa_enhanced_wrapper_fixed.py scripts/qa_enhanced_wrapper.py
        echo "   âœ… å·²æ›´æ–° qa_enhanced_wrapper.py"
    else
        echo "   âš ï¸  qa_enhanced_wrapper_fixed.py ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›¿æ¢"
        echo "   è¯·æ‰‹åŠ¨ä¸‹è½½å¹¶æ”¾ç½®è¯¥æ–‡ä»¶"
    fi
else
    echo "   âš ï¸  scripts/qa_enhanced_wrapper.py ä¸å­˜åœ¨"
fi
echo

# 5. è¿è¡Œè¯Šæ–­
echo "ğŸ“¦ æ­¥éª¤ 5/5: è¿è¡Œè¯Šæ–­..."
if [ -f "diagnose_llm.py" ]; then
    python3 diagnose_llm.py
else
    echo "   âš ï¸  diagnose_llm.py ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯Šæ–­"
    echo "   æ‰‹åŠ¨æµ‹è¯•: curl http://localhost:11434/api/tags"
fi
echo

# å®Œæˆ
echo "=================================="
echo "âœ… ä¿®å¤å®Œæˆï¼"
echo "=================================="
echo
echo "ä¸‹ä¸€æ­¥ï¼š"
echo "1. é‡å¯æœåŠ¡: python serve_qa_demo.py"
echo "2. æµ‹è¯•é—®ç­”: è®¿é—®ä½ çš„æœåŠ¡ç«¯å£"
echo "3. æŸ¥çœ‹æ—¥å¿—ç¡®è®¤ LLM å·¥ä½œæ­£å¸¸"
echo
echo "æ—¥å¿—ä½ç½®:"
echo "- Ollama: /tmp/ollama.log"
echo "- æœåŠ¡: æŸ¥çœ‹å¯åŠ¨å‘½ä»¤çš„è¾“å‡º"
echo