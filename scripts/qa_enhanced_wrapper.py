#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆ QA Wrapper - æ™ºèƒ½æ£€ç´¢ + ä¼˜åŒ– LLM
"""
import os
import sys
import json
import time
import logging
from pathlib import Path
from typing import Dict, List

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ¨æ€åŠ å…¥é¡¹ç›®æ ¹è·¯å¾„
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))
sys.path.insert(0, str(ROOT / "scripts"))

# ==================== å¯¼å…¥å¢å¼ºæ£€ç´¢å™¨ ====================
from scripts.enhanced_retriever import EnhancedRetriever

# ==================== LLM å®¢æˆ·ç«¯ ====================
try:
    from scripts.llm_client import chat_completion, LLMUnavailable, OLLAMA_MODEL, is_configured
    HAVE_LLM = True
    
    if not is_configured():
        logger.warning("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œ")
        HAVE_LLM = False
    else:
        logger.info(f"âœ… LLM å¯ç”¨: {OLLAMA_MODEL}")
        
except Exception as e:
    logger.error(f"âŒ LLM åŠ è½½å¤±è´¥: {e}")
    HAVE_LLM = False
    
    class LLMUnavailable(Exception): 
        pass
    
    def chat_completion(*_args, **_kwargs): 
        raise LLMUnavailable("LLM æœªåˆå§‹åŒ–")
    
    OLLAMA_MODEL = "unknown"

# ==================== åŠ è½½æ–‡æ¡£æ•°æ® ====================# ==================== åŠ è½½æ–‡æ¡£æ•°æ® ====================
PROGRAMS_PATH = ROOT / "public/data/ucl_programs.json"
SERVICES_PATH = ROOT / "public/data/ucl_services.json"

def _load_documents() -> List[dict]:
    """åŠ è½½æ‰€æœ‰æ–‡æ¡£"""
    documents = []
    
    # åŠ è½½ programs
    if PROGRAMS_PATH.exists():
        try:
            with open(PROGRAMS_PATH, 'r', encoding='utf-8') as f:
                programs = json.load(f)
                documents.extend(programs)
            logger.info(f"âœ… åŠ è½½ {len(programs)} ä¸ªè¯¾ç¨‹")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è¯¾ç¨‹å¤±è´¥: {e}")
    
    # åŠ è½½ services
    if SERVICES_PATH.exists():
        try:
            with open(SERVICES_PATH, 'r', encoding='utf-8') as f:
                services = json.load(f)
                documents.extend(services)
            logger.info(f"âœ… åŠ è½½ {len(services)} ä¸ªæœåŠ¡")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æœåŠ¡å¤±è´¥: {e}")
    
    return documents

# ==================== æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ ====================
def _generate_smart_answer(query: str, search_results: List[Dict]) -> str:
    """æ™ºèƒ½ç”Ÿæˆç­”æ¡ˆï¼ˆå……åˆ†åˆ©ç”¨sectionsä¿¡æ¯ï¼‰"""
    
    intent = search_results[0]['intent']
    
    # æ„å»ºå¯Œå«ä¸Šä¸‹æ–‡çš„ prompt
    context_parts = []
    
    for i, result in enumerate(search_results[:3], 1):
        doc = result['doc']
        title = doc.get('title', 'Unknown')
        url = doc.get('url', '')
        matched_sections = result.get('matched_sections', [])
        
        # æå–æœ€ç›¸å…³çš„sections
        section_texts = []
        for sec in matched_sections[:3]:  # å‰3ä¸ªæœ€ç›¸å…³section
            heading = sec['heading']
            text = sec['text'][:500]  # é™åˆ¶é•¿åº¦
            section_texts.append(f"  **{heading}**\n  {text}")
        
        context_parts.append(
            f"[{i}] {title}\n" + 
            "\n".join(section_texts) + 
            f"\n  Source: {url}"
        )
    
    context_str = "\n\n".join(context_parts)
    
    # æ ¹æ®æ„å›¾å®šåˆ¶ prompt
    intent_prompts = {
        'modules': """Focus on extracting course modules, curriculum structure, and what students will learn. 
If specific module names/codes are listed, include them. If only topics are mentioned, list the topics clearly.""",
        
        'requirements': """Focus on entry requirements, qualifications, English language requirements (IELTS/TOEFL), 
and any prerequisites. Be specific with numbers and scores.""",
        
        'career': """Focus on career prospects, graduate outcomes, employment opportunities, and potential career paths.""",
        
        'fees': """Focus on tuition fees, funding opportunities, scholarships, and financial information.""",
        
        'general': """Provide a comprehensive overview based on the available information."""
    }
    
    system_prompt = f"""You are a UCL course information assistant with access to detailed course documentation.

INSTRUCTIONS:
1. Answer based STRICTLY on the provided course sections
2. {intent_prompts.get(intent, intent_prompts['general'])}
3. Cite sources using [1], [2], [3]
4. If information is limited, acknowledge it but extract what's available
5. Use bullet points for lists
6. Keep answer under 250 words
7. Be natural and conversational in tone"""

    user_prompt = f"""Question: {query}

Available Course Information:
{context_str}

Please provide a clear, accurate answer based on the sections above."""

    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        logger.info(f"[LLM] è°ƒç”¨ Ollamaï¼Œä¸Šä¸‹æ–‡é•¿åº¦: {len(context_str)} å­—ç¬¦")
        answer = chat_completion(messages, temperature=0.3, timeout=120)
        
        return answer
        
    except LLMUnavailable as e:
        logger.warning(f"âš ï¸ LLM ä¸å¯ç”¨: {e}")
        return _generate_fallback_answer(search_results)
    except Exception as e:
        logger.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
        return _generate_fallback_answer(search_results)

def _generate_fallback_answer(search_results: List[Dict]) -> str:
    """é™çº§æ–¹æ¡ˆï¼šåŸºäºsectionsçš„æ™ºèƒ½æ‘˜è¦"""
    
    if not search_results:
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
    
    intent = search_results[0]['intent']
    answer_parts = []
    
    # æ ¹æ®æ„å›¾ç”Ÿæˆä¸åŒçš„å›ç­”æ¡†æ¶
    if intent == 'modules':
        answer_parts.append("Based on the course information:\n")
    elif intent == 'requirements':
        answer_parts.append("Entry requirements found:\n")
    elif intent == 'career':
        answer_parts.append("Career information:\n")
    else:
        answer_parts.append("Here's what I found:\n")
    
    # æå–å‰3ä¸ªæœ€ç›¸å…³æ–‡æ¡£çš„ä¿¡æ¯
    for i, result in enumerate(search_results[:3], 1):
        doc = result['doc']
        title = doc.get('title', 'Unknown')
        matched_sections = result.get('matched_sections', [])
        
        answer_parts.append(f"\n**{i}. {title}**")
        
        # æå–æœ€ç›¸å…³sectionçš„å…³é”®ä¿¡æ¯
        if matched_sections:
            best_section = matched_sections[0]
            heading = best_section['heading']
            text = best_section['text'][:400]
            
            # æ™ºèƒ½æˆªæ–­ï¼ˆæŒ‰å¥å­ï¼‰
            sentences = text.split('. ')
            summary = '. '.join(sentences[:3]) + '.'
            
            answer_parts.append(f"   â€¢ {heading}: {summary}")
    
    answer_parts.append("\n\nğŸ’¡ *For complete details, please visit the official UCL course pages.*")
    
    return '\n'.join(answer_parts)

# ==================== ä¸»å‡½æ•° ====================
# ==================== ä¸»å‡½æ•° ====================
def answer_enhanced(query: str, top_k: int = 8) -> dict:
    """å¢å¼ºç‰ˆé—®ç­”ï¼ˆä½¿ç”¨æ–°æ£€ç´¢å™¨ï¼‰"""
    start_time = time.time()
    
    logger.info(f"\n{'='*60}\næ”¶åˆ°æŸ¥è¯¢: {query}\n{'='*60}")
    
    # åŠ è½½æ•°æ®å’Œç´¢å¼•
    documents = _load_documents()
    
    if not documents:
        return {
            'intent': 'unknown',
            'answer': 'æŠ±æ­‰ï¼Œæ•°æ®æœªåŠ è½½ã€‚',
            'citations': [],
            'num_queries': 1,
            'num_docs': 0,
            'response_time': f"{time.time() - start_time:.2f}s"
        }
    
    # ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨
    retriever = EnhancedRetriever()
    search_results = retriever.search_with_context(query, documents, top_k)
    
    if not search_results:
        return {
            'intent': 'unknown',
            'answer': 'æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚',
            'citations': [],
            'num_queries': 1,
            'num_docs': 0,
            'response_time': f"{time.time() - start_time:.2f}s"
        }
    
    # ç”Ÿæˆç­”æ¡ˆ
    try:
        answer = _generate_smart_answer(query, search_results)
    except Exception as e:
        logger.error(f"âŒ ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
        answer = _generate_fallback_answer(search_results)
    
    # æ„å»ºå¼•ç”¨
    citations = []
    for result in search_results[:5]:
        doc = result['doc']
        citations.append({
            'title': doc.get('title', 'Unknown'),
            'url': doc.get('url', ''),
            'relevance_score': result['score']
        })
    
    response_time = time.time() - start_time
    logger.info(f"âœ… é—®ç­”å®Œæˆï¼Œè€—æ—¶: {response_time:.2f}s\n{'='*60}\n")
    
    return {
        'intent': search_results[0]['intent'],
        'answer': answer,
        'citations': citations,
        'num_queries': 1,
        'num_docs': len(search_results),
        'response_time': f"{response_time:.2f}s"
    }


# ==================== æµ‹è¯• ====================
# ==================== æµ‹è¯• ====================
if __name__ == "__main__":
    test_queries = [
        "Data Science MSc modules",
        "è®¡ç®—æœºç§‘å­¦ç¡•å£«çš„è¯­è¨€è¦æ±‚",
        "å¦‚ä½•é¢„çº¦å¿ƒç†å’¨è¯¢",
        "å•†ç§‘ç¡•å£«å…¥å­¦è¦æ±‚"
    ]
    
    print("\n" + "="*60)
    print("å¢å¼ºç‰ˆ QA ç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    
    for q in test_queries:
        print(f"\né—®é¢˜: {q}")
        result = answer_enhanced(q, top_k=5)
        print(f"\næ„å›¾: {result['intent']}")
        print(f"\nç­”æ¡ˆ:\n{result['answer']}")
        print(f"\nå¼•ç”¨: {len(result['citations'])} ä¸ªæ–‡æ¡£")
        for i, cite in enumerate(result['citations'][:3], 1):
            print(f"  {i}. {cite['title']} (score: {cite.get('relevance_score', 'N/A')})")
        print("-"*60)
