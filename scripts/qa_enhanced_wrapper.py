#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""qa_enhanced_wrapper.py - å®Œå…¨å¢å¼ºç‰ˆï¼ˆæ™ºèƒ½è¯­è¨€åˆ‡æ¢ï¼‰"""

import os, sys, json, time, logging, re
from pathlib import Path
from typing import List, Dict, Any

ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))
sys.path.insert(0, str(ROOT / "scripts"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("qa_enhanced_wrapper")

# ============ å¯¼å…¥ LLM å®¢æˆ·ç«¯ ============
try:
    from scripts.llm_client import chat_with_groq, is_configured as groq_configured
    logger.info("âœ… Using llm_client.py")
except Exception as e1:
    try:
        from scripts.groq_client import chat_with_groq, is_configured as groq_configured
        logger.info("âœ… Using groq_client.py")
    except Exception as e2:
        logger.warning(f"âŒ LLM import failed: {e1}, {e2}")
        def groq_configured(): return False
        def chat_with_groq(*a, **k): raise Exception("LLM not available")

# ============ å¯¼å…¥æ£€ç´¢å™¨ ============
try:
    from scripts.enhanced_retriever import EnhancedRetriever
    HAVE_RETRIEVER = True
    logger.info("âœ… Enhanced retriever loaded")
except Exception as e:
    HAVE_RETRIEVER = False
    logger.warning(f"âš ï¸  Retriever not available: {e}")

PROGRAMS_PATH = ROOT / "public/data/ucl_programs.json"
SERVICES_PATH = ROOT / "public/data/ucl_services.json"

# ============ ğŸ”¥ è¯­è¨€æ£€æµ‹ ============
def detect_language(text: str) -> str:
    """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    if chinese_chars > 0:
        return "zh"
    return "en"

# ============ æ–‡æ¡£åŠ è½½ ============
def _load_documents() -> List[Dict]:
    documents = []
    for path, name in [(PROGRAMS_PATH, "programs"), (SERVICES_PATH, "services")]:
        if path.exists():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    documents.extend(data)
                logger.info(f"âœ… Loaded {len(data)} {name}")
            except Exception as e:
                logger.error(f"âŒ Load {name} failed: {e}")
    return documents

# ============ æ„å›¾æ£€æµ‹ ============
def _detect_intent(q: str) -> str:
    ql = q.lower()
    if any(k in ql for k in ['language', 'è¯­è¨€', 'ielts', 'toefl', 'requirement', 'è¦æ±‚']):
        return 'requirements'
    if any(k in ql for k in ['module', 'è¯¾ç¨‹', 'core', 'curriculum', 'æ¨¡å—']):
        return 'modules'
    if any(k in ql for k in ['career', 'counseling', 'book', 'é¢„çº¦', 'å°±ä¸š']):
        return 'services'
    if any(k in ql for k in ['fee', 'tuition', 'cost', 'å­¦è´¹', 'è´¹ç”¨']):
        return 'fees'
    return 'general'

# ============ ç®€å•æœç´¢ï¼ˆfallbackï¼‰============
def _simple_fallback_search(query: str, documents: List[Dict], top_k: int = 8) -> List[Dict]:
    qlower = query.lower()
    results = []
    for doc in documents:
        text = ' '.join([doc.get('title','')] + [
            f"{s.get('heading','')} {s.get('text','')}" 
            for s in doc.get('sections',[])[:5]
        ]).lower()
        score = sum(text.count(w) * 2 for w in qlower.split() if len(w) > 2)
        if score > 0:
            results.append({
                'doc': doc, 
                'score': score, 
                'intent': _detect_intent(query)
            })
    results.sort(key=lambda x: x['score'], reverse=True)
    return results[:top_k]

# ============ æ„å»ºä¸Šä¸‹æ–‡ ============
def _build_context_from_results(results: List[Dict]) -> str:
    parts = []
    for r in results[:3]:
        doc = r.get('doc', {})
        title = doc.get('title', 'Unknown')
        for s in doc.get('sections', [])[:4]:
            h, t = s.get('heading', ''), s.get('text', '')[:900]
            if t and len(t) > 50:
                parts.append(f"ã€{title} - {h}ã€‘\n{t}")
                break
    return "\n\n".join(parts)

# ============ æ¸…ç†æ–‡æœ¬ ============
def _clean_text(text: str) -> str:
    if not text: return ""
    noise = ['click here', 'view details', 'read more', 'for more information']
    for n in noise:
        text = text.replace(n, '')
    return '. '.join([s.strip() for s in text.split('.')[:5] if len(s) > 40])

# ============ ğŸ”¥ æå–å…³é”®ä¿¡æ¯ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰============
def _extract_key_info(results: List[Dict], lang: str) -> str:
    if not results:
        return "æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚" if lang == "zh" else "No relevant information found."
    
    extracted = []
    for r in results[:3]:
        doc = r.get('doc', {})
        title = doc.get('title', '')
        for s in doc.get('sections', [])[:4]:
            heading = s.get('heading', '')
            text = _clean_text(s.get('text', ''))
            if len(text) > 100:
                extracted.append(f"**{title} - {heading}**:\n{text[:600]}")
                break
    
    if not extracted:
        return "æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä½†æ— æ³•æå–è¯¦æƒ…ã€‚" if lang == "zh" else "Found content but unable to extract details."
    
    return '\n\n'.join(extracted[:2])

# ============ ğŸ”¥ æ™ºèƒ½ç”Ÿæˆç­”æ¡ˆï¼ˆå¼ºåŒ–è¯­è¨€æ§åˆ¶ï¼‰============
def _generate_smart_answer_using_llm(
    query: str, 
    results: List[Dict], 
    language: str = "auto"
) -> str:
    """ä½¿ç”¨ LLM ç”Ÿæˆæ™ºèƒ½ç­”æ¡ˆï¼Œå¼ºåˆ¶è¯­è¨€æ§åˆ¶"""
    
    # ğŸ”¥ è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    if language == "auto" or not language:
        language = detect_language(query)
        logger.info(f"ğŸŒ è‡ªåŠ¨æ£€æµ‹è¯­è¨€: {language}")
    
    context = _build_context_from_results(results)
    
    if language == "zh":
        # ğŸ”¥ ä¸­æ–‡ Prompt - æåº¦å¼ºåŒ–
        system = """ä½ æ˜¯ UCL ä¿¡æ¯åŠ©æ‰‹ã€‚

ã€ä¸¥æ ¼è§„åˆ™ã€‘
1. ä½ å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼Œç»å¯¹ä¸è¦ä½¿ç”¨è‹±æ–‡
2. ä»æ–‡æ¡£ä¸­æå–å‡†ç¡®ä¿¡æ¯
3. ä½¿ç”¨ â€¢ ç¬¦å·åˆ—å‡ºè¦ç‚¹
4. ä¿æŒç®€æ´ï¼Œå°‘äº150å­—
5. å¦‚æœæ–‡æ¡£æ˜¯è‹±æ–‡ï¼Œç¿»è¯‘æˆä¸­æ–‡åå›ç­”

è®°ä½ï¼šä½ çš„å›ç­”å¿…é¡»å…¨éƒ¨æ˜¯ä¸­æ–‡ï¼"""
        
        user = f"""æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•è‹±æ–‡ã€‚"""
    
    else:
        # è‹±æ–‡ Prompt
        system = """You are a UCL information assistant.

Rules:
- Extract accurate information from documents
- Answer in English only
- Use â€¢ for bullet points
- Keep under 150 words
- Be specific and factual"""
        
        user = f"""Documents:
{context}

User Question: {query}

Answer in English."""
    
    messages = [
        {"role": "system", "content": system},
        {"role": "user", "content": user}
    ]
    
    try:
        if groq_configured():
            logger.info(f"ğŸ¤– è°ƒç”¨ LLM (language={language})...")
            ans = chat_with_groq(messages, temperature=0.1)
            
            # ğŸ”¥ éªŒè¯è¯­è¨€æ˜¯å¦æ­£ç¡®
            if language == "zh":
                chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', ans))
                if chinese_chars < 10:  # ä¸­æ–‡å­—ç¬¦å¤ªå°‘
                    logger.warning("âš ï¸  LLM è¿”å›äº†è‹±æ–‡ï¼Œä½¿ç”¨ fallback")
                    return _extract_key_info(results, language)
            
            if ans and len(ans) > 30:
                logger.info(f"âœ… LLM å›ç­”æˆåŠŸ ({len(ans)} chars)")
                return ans
    
    except Exception as e:
        logger.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
    
    # Fallback
    logger.info("âš ï¸  ä½¿ç”¨ fallback æå–")
    return _extract_key_info(results, language)

# ============ ğŸ”¥ ä¸»å‡½æ•° ============
def answer_enhanced(
    query: str, 
    top_k: int = 8, 
    language: str = "auto"
) -> Dict[str, Any]:
    """å¢å¼ºç‰ˆé—®ç­” - æ”¯æŒè‡ªåŠ¨è¯­è¨€æ£€æµ‹"""
    
    start = time.time()
    
    # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    if language == "auto" or not language:
        language = detect_language(query)
    
    logger.info(f"{'='*60}")
    logger.info(f"ğŸ” Query: {query}")
    logger.info(f"ğŸŒ Language: {language}")
    logger.info(f"{'='*60}")
    
    # åŠ è½½æ–‡æ¡£
    docs = _load_documents()
    if not docs:
        return {
            "intent": "error",
            "answer": "æ•°æ®æœªåŠ è½½" if language == "zh" else "Data not loaded",
            "citations": [],
            "rewritten_queries": [],
            "reranked": [],
            "response_time": f"{time.time()-start:.2f}s"
        }
    
    # æ£€ç´¢
    search_results = []
    if HAVE_RETRIEVER:
        try:
            retriever = EnhancedRetriever()
            raw = retriever.search_with_context(query, docs, top_k)
            search_results = [
                {
                    'doc': r.get('doc', r),
                    'score': r.get('score', 0),
                    'intent': _detect_intent(query)
                } 
                for r in raw
            ]
            logger.info(f"âœ… Retriever è¿”å› {len(search_results)} ä¸ªç»“æœ")
        except Exception as e:
            logger.warning(f"âš ï¸  Retriever å¤±è´¥: {e}")
    
    if not search_results:
        logger.info("âš ï¸  ä½¿ç”¨ fallback æœç´¢")
        search_results = _simple_fallback_search(query, docs, top_k)
    
    # ç”Ÿæˆç­”æ¡ˆ
    answer = _generate_smart_answer_using_llm(query, search_results, language)
    
    # æ„å»ºå¼•ç”¨
    citations = [
        {
            'title': d.get('doc', {}).get('title', ''),
            'url': d.get('doc', {}).get('url', ''),
            'relevance_score': d.get('score', 0)
        }
        for d in search_results[:6]
    ]
    
    rt = f"{time.time()-start:.2f}s"
    logger.info(f"âœ… å®Œæˆ: {rt}")
    
    return {
        "intent": search_results[0].get('intent', 'general') if search_results else "unknown",
        "answer": answer,
        "citations": citations,
        "rewritten_queries": [],  # ğŸ”¥ å‰ç«¯éœ€è¦
        "reranked": search_results,
        "response_time": rt
    }